{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Job tag classification",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1T3mNKzfwerLyHICDIvz_-PDWKdYHhDxV",
      "authorship_tag": "ABX9TyPxcZI2XpPMMyWMfI82EJPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmicishan/Classification-on-text-data/blob/main/Job_tag_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX4_pxjO3niU"
      },
      "source": [
        "# **Importing Libraries and Dataset**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SsUPczU3ZTM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZD7blxH3wff"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/73-Strings/Train.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwMjC-si37Kr"
      },
      "source": [
        "X = df.iloc[:,1].values\n",
        "y = df.iloc[:,-1].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROxjF3OG-QYZ"
      },
      "source": [
        "# **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMvyusuY5kbo"
      },
      "source": [
        "#Removing contraction from the text.\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ete0xAXB7LFp"
      },
      "source": [
        "#We are removing the words from the stop words list: 'no', 'nor', 'not' \n",
        "#we are including them into stop words list\n",
        "\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ3czpZ_72vW",
        "outputId": "48509b42-c3eb-4963-c2e9-b47f99f78d3f"
      },
      "source": [
        "from tqdm import tqdm\n",
        "preprocessed_description = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(X):\n",
        "    sentance = str(sentance)\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance) #Remove links\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text() #Remove tags\n",
        "    sentance = decontracted(sentance) #Remove Contraction\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip() #Remove words with numbers\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance) #Remove Special Character\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "    preprocessed_description.append(sentance.strip())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6045/6045 [00:02<00:00, 2713.29it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3gAGTio-f-u"
      },
      "source": [
        "# **Featurization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqZ1R7Ln-pcu"
      },
      "source": [
        "## *Bag of Words*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8sZn1kG-jj0",
        "outputId": "24214144-3510-4432-8df6-208892e73add"
      },
      "source": [
        "#BoW\n",
        "count_vect = CountVectorizer() #in scikit-learn\n",
        "count_vect.fit(preprocessed_description)\n",
        "print(\"some feature names : \", count_vect.get_feature_names()[:10])\n",
        "print('='*50)\n",
        "\n",
        "final_counts = count_vect.transform(preprocessed_description)\n",
        "print(\"the type of count vectorizer : \",type(final_counts))\n",
        "print(\"the shape of out text BOW vectorizer : \",final_counts.get_shape())\n",
        "print(\"the number of unique words : \", final_counts.get_shape()[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "some feature names :  ['aaa', 'aad', 'aadc', 'aaftink', 'aagp', 'aagps', 'aallon', 'aam', 'aaon', 'aap']\n",
            "==================================================\n",
            "the type of count vectorizer :  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text BOW vectorizer :  (6045, 34494)\n",
            "the number of unique words :  34494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b9CYB_WfsSj"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_counts, y, test_size = 0.25)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUA5uU7bardz"
      },
      "source": [
        "**Training bag of word model on SVM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7igBYxtmXc0y",
        "outputId": "cca4f49a-893a-4634-cc9d-382db1a8b4a9"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "bow_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of bag of words model in SVM alorithm : \",bow_svm)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bag of words model in SVM alorithm :  0.621031746031746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ocfi3dHvfZ23"
      },
      "source": [
        "**Training bag of word model on Random Forest algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-s99g66a-tt",
        "outputId": "d1cc350c-61de-4391-97a4-134ca8b12211"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "bow_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of bag of words model in Random Forest algorithm : \",bow_rf)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bag of words model in Random Forest algorithm :  0.40811622954167515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi993QO2fcvg"
      },
      "source": [
        "**Training bag of word model on Naive Bayes algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PstXwnMadsN2",
        "outputId": "44ea35c6-2b94-4bb3-cc1f-9193325860e3"
      },
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train_dense, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "bow_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of bag of words model in Naive Bayes algorithm : \",bow_nb)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bag of words model in Naive Bayes algorithm :  0.5244708994708994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY1yXUfFJhQU"
      },
      "source": [
        "##*Bi-Grams and n-Grams*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcRR5tAeDQ1I",
        "outputId": "f6e5ee78-0a3d-488b-9580-8ddc1f4ef895"
      },
      "source": [
        "#bi-gram, tri-gram and n-gram\n",
        "\n",
        "count_vect = CountVectorizer(ngram_range=(1,2), min_df=10, max_features=5000)\n",
        "final_bigram_counts = count_vect.fit_transform(preprocessed_description)\n",
        "print(\"the type of count vectorizer : \",type(final_bigram_counts))\n",
        "print(\"the shape of out text BOW vectorizer : \",final_bigram_counts.get_shape())\n",
        "print(\"the number of unique words including both unigrams and bigrams : \", final_bigram_counts.get_shape()[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the type of count vectorizer :  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text BOW vectorizer :  (6045, 5000)\n",
            "the number of unique words including both unigrams and bigrams :  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9myLuRufw2N"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_bigram_counts, y, test_size = 0.25)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-KnUJ8Wf0u7"
      },
      "source": [
        "**Training unigrams/bigrams model on SVM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x24eHh6wgEMA",
        "outputId": "4cdd8f5c-9421-4aa3-978f-0a77a7677117"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "grams_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of unigrams/bigrams model in SVM algorithm : \",grams_svm)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigrams/bigrams model in SVM algorithm :  0.6283068783068783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCz0atycf7o0"
      },
      "source": [
        "**Training unigrams/bigrams model on Random Forest algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2v0LhEpgEoW",
        "outputId": "30a71dba-d1cf-448d-eaa9-b7e13027c244"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "grams_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of unigrams/bigrams model in Random Forest algorithm : \",grams_rf)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigrams/bigrams model in Random Forest algorithm :  0.4092355418113215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peTsbhgUgCKy"
      },
      "source": [
        "**Training unigrams/bigrams model on Naive Bayes algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuIL06tigFDg",
        "outputId": "472ce093-f023-46cb-caf0-e10dcab7ba84"
      },
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train_dense, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "grams_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of unigrams/bigrams model in Naive Bayes algorithm : \",grams_nb)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigrams/bigrams model in Naive Bayes algorithm :  0.5304232804232805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJid8w54JiC1"
      },
      "source": [
        "## *TF_IDF*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuq3Nt_1DVWJ",
        "outputId": "f251c005-00b2-4948-82ea-a2b07be6e54c"
      },
      "source": [
        "#tf-idf\n",
        "\n",
        "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
        "tf_idf_vect.fit(preprocessed_description)\n",
        "print(\"some sample features(unique words in the corpus)\",tf_idf_vect.get_feature_names()[0:10])\n",
        "print('='*50)\n",
        "\n",
        "final_tf_idf = tf_idf_vect.transform(preprocessed_description)\n",
        "print(\"the type of count vectorizer \",type(final_tf_idf))\n",
        "print(\"the shape of out text TFIDF vectorizer \",final_tf_idf.get_shape())\n",
        "print(\"the number of unique words including both unigrams and bigrams \", final_tf_idf.get_shape()[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "some sample features(unique words in the corpus) ['ab', 'ab formerly', 'ab publ', 'ab sweden', 'ability', 'abitibi', 'abitibi greenstone', 'able', 'abroad', 'absorption']\n",
            "==================================================\n",
            "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text TFIDF vectorizer  (6045, 7682)\n",
            "the number of unique words including both unigrams and bigrams  7682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xf2YvQEmCMW"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_tf_idf, y, test_size = 0.25)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doPCNC5Rkixw"
      },
      "source": [
        "**Training TF_IDF model on SVM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDfTaJ7Tl-Fw",
        "outputId": "66617cf3-645d-4675-8865-031c92e28cde"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "idf_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of TF-IDF model in SVM algorithm : \",idf_svm)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF-IDF model in SVM algorithm :  0.6825396825396826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngUzNjqzki9S"
      },
      "source": [
        "**Training TF_IDF model on Random Forest algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zOn6fiEl-jI",
        "outputId": "9e46e5ea-2826-4f88-bd26-46d469139335"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "idf_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of TF_IDF model in Random Forest algorithm : \",idf_rf)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF_IDF model in Random Forest algorithm :  0.41208341842440516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeyIMRFqkjI-"
      },
      "source": [
        "**Training TF_IDF model on Naive Bayes algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3jSpG7Ml--T",
        "outputId": "6037b58c-88cf-447f-c8fe-4241d2db43a6"
      },
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train_dense, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "idf_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of TF_IDF model in Naive Bayes algorithm : \",idf_nb)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF_IDF model in Naive Bayes algorithm :  0.5357142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpkrMlbCJ05D"
      },
      "source": [
        "## *Word2Vec*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmEqjyi5KNpj",
        "outputId": "43c8c3ed-784d-4742-e900-a4baecb75afd"
      },
      "source": [
        "#Training Word2Vec using our own Text corpus.\n",
        "\n",
        "list_of_sentance=[]\n",
        "for sentance in preprocessed_description:\n",
        "    list_of_sentance.append(sentance.split())\n",
        "\n",
        "w2v_model=Word2Vec(list_of_sentance,min_count=5,size=50, workers=4)\n",
        "print(\"Words similar to Company according to our corpus : \",w2v_model.wv.most_similar('company'))\n",
        "print('='*50)\n",
        "print(\"Words similar to Technologies according to our corpus : \",w2v_model.wv.most_similar('technologies'))\n",
        "\n",
        "w2v_words = list(w2v_model.wv.vocab)\n",
        "print('='*50)\n",
        "print(\"Number of words that occured minimum 5 times : \",len(w2v_words))\n",
        "print(\"Sample words \", w2v_words[0:50])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words similar to Company according to our corpus :  [('principally', 0.6553246974945068), ('selling', 0.6519771218299866), ('empowered', 0.6504414677619934), ('tackle', 0.6491935849189758), ('acquiring', 0.6440767049789429), ('several', 0.6370248794555664), ('owning', 0.6361712217330933), ('sector', 0.6359339356422424), ('provision', 0.6304469108581543), ('cannabis', 0.6293812394142151)]\n",
            "==================================================\n",
            "Words similar to Technologies according to our corpus :  [('diagnostics', 0.9453083872795105), ('bd', 0.9140072464942932), ('science', 0.8999008536338806), ('advanced', 0.8853769898414612), ('semiconductor', 0.8843767642974854), ('biomedical', 0.8799190521240234), ('pharmaceutical', 0.8762993812561035), ('medical', 0.8727603554725647), ('laboratory', 0.8724081516265869), ('pharmaceuticals', 0.8669586181640625)]\n",
            "==================================================\n",
            "Number of words that occured minimum 5 times :  8311\n",
            "Sample words  ['partners', 'inc', 'provides', 'advertising', 'agency', 'services', 'specializing', 'direct', 'response', 'media', 'campaigns', 'also', 'owns', 'distribution', 'rights', 'number', 'products', 'acquired', 'business', 'consists', 'two', 'operating', 'sectors', 'year', 'ended', 'december', 'internally', 'developed', 'marketed', 'lines', 'branded', 'extreme', 'beam', 'light', 'company', 'obtained', 'exclusive', 'five', 'marketing', 'hook', 'anti', 'mist', 'organized', 'power', 'solutions', 'purpose', 'selling', 'installing', 'servicing', 'integrated']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0_YDd2nMNuJ"
      },
      "source": [
        "## *Converting text into vectors using Avg W2V and TFIDF-W2V*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-LHX9i8MZR7"
      },
      "source": [
        "### *Average Word2Vec*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IGQMB6TMBov",
        "outputId": "049f79ca-bd62-412d-dde5-dd11ea195e94"
      },
      "source": [
        "# average Word2Vec\n",
        "# compute average word2vec for each description.\n",
        "sent_vectors = []; # the avg-w2v for each sentence/description is stored in this list\n",
        "for sent in tqdm(list_of_sentance): # for each description/sentence\n",
        "    sent_vec = np.zeros(50) \n",
        "    cnt_words =0; # num of words with a valid vector in the sentence/description\n",
        "    for word in sent: # for each word in a description/sentence\n",
        "        if word in w2v_words:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words += 1\n",
        "    if cnt_words != 0:\n",
        "        sent_vec /= cnt_words\n",
        "    sent_vectors.append(sent_vec)\n",
        "\n",
        "print(len(sent_vectors))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6045/6045 [00:20<00:00, 297.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-AdSP5PnaDn"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(sent_vectors, y, test_size = 0.25)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtoieyuunaVO"
      },
      "source": [
        "**Training Average Word2Vec model on SVM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-w8KveFnuUI",
        "outputId": "d55e9a71-128d-49fc-85cc-fd3604c9ca25"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "w2v_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of Word2Vec model in SVM algorithm : \",w2v_svm)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Word2Vec model in SVM algorithm :  0.34656084656084657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mmzpBnOnagu"
      },
      "source": [
        "**Training Average Word2Vec model on Random Forest algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X0JAN4Dnuwh",
        "outputId": "85f5a763-04fe-4abe-e75a-6bbc4df81f01"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "w2v_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of Word2Vec model in Random Forest algorithm : \",w2v_rf)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Word2Vec model in Random Forest algorithm :  0.44627933210802195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXEQzv_5nasN"
      },
      "source": [
        "**Training Average Word2Vec model on Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cmdGSqwnvL9",
        "outputId": "de6feb08-d2a0-4e68-d531-df5d40f88a19"
      },
      "source": [
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "w2v_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of Word2Vec model in Naive Bayes algorithm : \",w2v_nb)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Word2Vec model in Naive Bayes algorithm :  0.4312169312169312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw7CjRwaPR8d"
      },
      "source": [
        "### *TF-IDF Word2Vec*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP4xeP5FNeEt",
        "outputId": "7a926edc-0cd5-476d-ee6f-79e260246fde"
      },
      "source": [
        "model = TfidfVectorizer()\n",
        "model.fit(preprocessed_description)\n",
        "# we are converting a dictionary with word as a key, and the idf as a value\n",
        "dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))\n",
        "\n",
        "# TF-IDF weighted Word2Vec\n",
        "tfidf_feat = model.get_feature_names() # tfidf words/col-names\n",
        "\n",
        "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/description is stored in this list\n",
        "row=0;\n",
        "for sent in tqdm(list_of_sentance): # for each description/sentence \n",
        "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
        "    weight_sum =0; # num of words with a valid vector in the sentence/description\n",
        "    for word in sent: # for each word in a description/sentence\n",
        "        if word in w2v_words and word in tfidf_feat:\n",
        "            vec = w2v_model.wv[word]\n",
        "            # dictionary[word] = idf value of word in whole courpus\n",
        "            # sent.count(word) = tf valeus of word in this review\n",
        "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
        "            sent_vec += (vec * tf_idf)\n",
        "            weight_sum += tf_idf\n",
        "    if weight_sum != 0:\n",
        "        sent_vec /= weight_sum\n",
        "    tfidf_sent_vectors.append(sent_vec)\n",
        "    row += 1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6045/6045 [02:42<00:00, 37.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdZJ5EBJnxZX"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_sent_vectors, y, test_size = 0.25)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEn9ShRonxov"
      },
      "source": [
        "**Training TF-IDF Word2Vec model on SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YMklHX5oIrY",
        "outputId": "c87e66cf-6545-457b-a1c9-ab090b0fd13a"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "tfw2v_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of TF-IDF Word2Vec model in SVM algorithm : \",tfw2v_svm)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF-IDF Word2Vec model in SVM algorithm :  0.2791005291005291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLHTQNjBnx0t"
      },
      "source": [
        "**Training TF-IDF Word2Vec model on Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maQzrgPjoJGF",
        "outputId": "822f59c5-d14f-4699-f91b-2348da683d59"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "tfw2v_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of TF_IDF Word2Vec model in Random Forest algorithm : \",tfw2v_rf)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF_IDF Word2Vec model in Random Forest algorithm :  0.45443689159883693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji9XJRbknx-y"
      },
      "source": [
        "**Training TF-IDF Word2Vec model on Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF0uCxznoJkq",
        "outputId": "546c752b-3669-4bc3-e50c-17745e60c229"
      },
      "source": [
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "tfw2v_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of TF_IDF Word2Vec model in Naive Bayes algorithm : \",tfw2v_nb)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF_IDF Word2Vec model in Naive Bayes algorithm :  0.3994708994708995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRd5bAgzrP5_"
      },
      "source": [
        "# **Printing out table of accuracies on different models and algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LMH2mbCl7Xn",
        "outputId": "035ac96e-63e2-47b0-9bd9-bc6343103f21"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "accuracy = {\n",
        "    \"Bag of word\": {\n",
        "        \"SVM\": {\n",
        "            \"acc\": bow_svm\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"acc\": bow_rf\n",
        "        },\n",
        "        \"Naive Bayes\": {\n",
        "            \"acc\": bow_nb\n",
        "        }\n",
        "    },\n",
        "    \"Bi-grams and N-grams\": {\n",
        "        \"SVM\": {\n",
        "            \"acc\": grams_svm\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"acc\": grams_rf\n",
        "        },\n",
        "        \"Naive Bayes\": {\n",
        "            \"acc\": grams_nb\n",
        "        }\n",
        "    },\n",
        "    \"TF-IDF\": {\n",
        "        \"SVM\": {\n",
        "            \"acc\": idf_svm\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"acc\": idf_rf\n",
        "        },\n",
        "        \"Naive Bayes\": {\n",
        "            \"acc\": idf_nb\n",
        "        }\n",
        "    },\n",
        "    \"Average Word2Vec\": {\n",
        "        \"SVM\": {\n",
        "            \"acc\": w2v_svm\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"acc\": w2v_rf\n",
        "        },\n",
        "        \"Naive Bayes\": {\n",
        "            \"acc\": w2v_nb\n",
        "        }\n",
        "    },\n",
        "    \"Tf-IDF word2vec\": {\n",
        "        \"SVM\": {\n",
        "            \"acc\": tfw2v_svm\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"acc\": tfw2v_rf\n",
        "        },\n",
        "        \"Naive Bayes\": {\n",
        "            \"acc\": tfw2v_nb\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "table_fields = ['Model', 'Algorithm', 'Accuracy']\n",
        "pt = PrettyTable(table_fields)\n",
        "pt.padding_width = 5\n",
        "pt.title = 'Accuracy'\n",
        "for accuracy1, technique in accuracy.items():\n",
        "    pt.add_row([\"{}\".format(accuracy1), \"\", \"\"])\n",
        "    for name, algo_acc in technique.items():\n",
        "        pt.add_row([\"\", name, algo_acc[\"acc\"]])\n",
        "print(pt)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------+\n",
            "|                                      Accuracy                                      |\n",
            "+------------------------------+-----------------------+-----------------------------+\n",
            "|            Model             |       Algorithm       |           Accuracy          |\n",
            "+------------------------------+-----------------------+-----------------------------+\n",
            "|         Bag of word          |                       |                             |\n",
            "|                              |          SVM          |      0.621031746031746      |\n",
            "|                              |     Random Forest     |     0.40811622954167515     |\n",
            "|                              |      Naive Bayes      |      0.5244708994708994     |\n",
            "|     Bi-grams and N-grams     |                       |                             |\n",
            "|                              |          SVM          |      0.6283068783068783     |\n",
            "|                              |     Random Forest     |      0.4092355418113215     |\n",
            "|                              |      Naive Bayes      |      0.5304232804232805     |\n",
            "|            TF-IDF            |                       |                             |\n",
            "|                              |          SVM          |      0.6825396825396826     |\n",
            "|                              |     Random Forest     |     0.41208341842440516     |\n",
            "|                              |      Naive Bayes      |      0.5357142857142857     |\n",
            "|       Average Word2Vec       |                       |                             |\n",
            "|                              |          SVM          |     0.34656084656084657     |\n",
            "|                              |     Random Forest     |     0.44627933210802195     |\n",
            "|                              |      Naive Bayes      |      0.4312169312169312     |\n",
            "|       Tf-IDF word2vec        |                       |                             |\n",
            "|                              |          SVM          |      0.2791005291005291     |\n",
            "|                              |     Random Forest     |     0.45443689159883693     |\n",
            "|                              |      Naive Bayes      |      0.3994708994708995     |\n",
            "+------------------------------+-----------------------+-----------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}