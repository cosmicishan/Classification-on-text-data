{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "73_strings",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1T3mNKzfwerLyHICDIvz_-PDWKdYHhDxV",
      "authorship_tag": "ABX9TyPhp/SE5d4IdGfkTPqB3Xrj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmicishan/Classification-on-text-data/blob/main/73_strings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX4_pxjO3niU"
      },
      "source": [
        "# **Importing Libraries and Dataset**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SsUPczU3ZTM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZD7blxH3wff"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/73-Strings/Train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwMjC-si37Kr"
      },
      "source": [
        "X = df.iloc[:,1].values\n",
        "y = df.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROxjF3OG-QYZ"
      },
      "source": [
        "# **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMvyusuY5kbo"
      },
      "source": [
        "#Removing contraction from the text.\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ete0xAXB7LFp"
      },
      "source": [
        "#We are removing the words from the stop words list: 'no', 'nor', 'not' \n",
        "#we are including them into stop words list\n",
        "\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ3czpZ_72vW",
        "outputId": "89442127-b6e9-4664-d271-0dd978d904fc"
      },
      "source": [
        "from tqdm import tqdm\n",
        "preprocessed_description = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(X):\n",
        "    sentance = str(sentance)\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance) #Remove links\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text() #Remove tags\n",
        "    sentance = decontracted(sentance) #Remove Contraction\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip() #Remove words with numbers\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance) #Remove Special Character\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "    preprocessed_description.append(sentance.strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6045/6045 [00:02<00:00, 2713.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3gAGTio-f-u"
      },
      "source": [
        "# **Featurization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqZ1R7Ln-pcu"
      },
      "source": [
        "## *Bag of Words*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8sZn1kG-jj0",
        "outputId": "69bb4b10-24b8-4095-c8ea-274c989ac725"
      },
      "source": [
        "#BoW\n",
        "count_vect = CountVectorizer() #in scikit-learn\n",
        "count_vect.fit(preprocessed_description)\n",
        "print(\"some feature names : \", count_vect.get_feature_names()[:10])\n",
        "print('='*50)\n",
        "\n",
        "final_counts = count_vect.transform(preprocessed_description)\n",
        "print(\"the type of count vectorizer : \",type(final_counts))\n",
        "print(\"the shape of out text BOW vectorizer : \",final_counts.get_shape())\n",
        "print(\"the number of unique words : \", final_counts.get_shape()[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "some feature names :  ['aaa', 'aad', 'aadc', 'aaftink', 'aagp', 'aagps', 'aallon', 'aam', 'aaon', 'aap']\n",
            "==================================================\n",
            "the type of count vectorizer :  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text BOW vectorizer :  (6045, 34494)\n",
            "the number of unique words :  34494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b9CYB_WfsSj"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_counts, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUA5uU7bardz"
      },
      "source": [
        "**Training bag of word model on SVM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7igBYxtmXc0y",
        "outputId": "c96bb82a-1a27-4a68-8222-6bd132c6fa7c"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "bow_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of bag of words model in SVM alorithm : \",bow_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bag of words model in SVM alorithm :  0.6223544973544973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ocfi3dHvfZ23"
      },
      "source": [
        "**Training bag of word model on Random Forest algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-s99g66a-tt",
        "outputId": "ac3932a5-495b-42a2-ee79-460e9b56f143"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "bow_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of bag of words model in Random Forest algorithm : \",bow_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bag of words model in Random Forest algorithm :  0.40370899825927975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi993QO2fcvg"
      },
      "source": [
        "**Training bag of word model on Naive Bayes algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PstXwnMadsN2",
        "outputId": "d5d02159-e310-47e6-b1e5-d0d813ccdd93"
      },
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train_dense, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "bow_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of bag of words model in Naive Bayes algorithm : \",bow_nb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bag of words model in Naive Bayes algorithm :  0.5205026455026455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY1yXUfFJhQU"
      },
      "source": [
        "##*Bi-Grams and n-Grams*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcRR5tAeDQ1I",
        "outputId": "6d18a876-db23-4d86-f06b-a0da90cb364c"
      },
      "source": [
        "#bi-gram, tri-gram and n-gram\n",
        "\n",
        "count_vect = CountVectorizer(ngram_range=(1,2), min_df=10, max_features=5000)\n",
        "final_bigram_counts = count_vect.fit_transform(preprocessed_description)\n",
        "print(\"the type of count vectorizer : \",type(final_bigram_counts))\n",
        "print(\"the shape of out text BOW vectorizer : \",final_bigram_counts.get_shape())\n",
        "print(\"the number of unique words including both unigrams and bigrams : \", final_bigram_counts.get_shape()[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the type of count vectorizer :  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text BOW vectorizer :  (6045, 5000)\n",
            "the number of unique words including both unigrams and bigrams :  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9myLuRufw2N"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_bigram_counts, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-KnUJ8Wf0u7"
      },
      "source": [
        "**Training unigrams/bigrams model on SVM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x24eHh6wgEMA",
        "outputId": "c161326e-645e-4348-c16f-8abea512cf91"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "grams_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of unigrams/bigrams model in SVM algorithm : \",grams_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigrams/bigrams model in SVM algorithm :  0.623015873015873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCz0atycf7o0"
      },
      "source": [
        "**Training unigrams/bigrams model on Random Forest algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2v0LhEpgEoW",
        "outputId": "84ef5c85-f058-4830-abe8-24050598feb6"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "grams_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of unigrams/bigrams model in Random Forest algorithm : \",grams_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigrams/bigrams model in Random Forest algorithm :  0.4136340208691931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peTsbhgUgCKy"
      },
      "source": [
        "**Training unigrams/bigrams model on Naive Bayes algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuIL06tigFDg",
        "outputId": "0753073c-d0f2-4322-ce3f-c5c3415c8a07"
      },
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train_dense, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "grams_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of unigrams/bigrams model in Naive Bayes algorithm : \",grams_nb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigrams/bigrams model in Naive Bayes algorithm :  0.5205026455026455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJid8w54JiC1"
      },
      "source": [
        "## *TF_IDF*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuq3Nt_1DVWJ",
        "outputId": "9dac0cbf-08d6-4b36-fa1f-803746f3d41b"
      },
      "source": [
        "#tf-idf\n",
        "\n",
        "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
        "tf_idf_vect.fit(preprocessed_description)\n",
        "print(\"some sample features(unique words in the corpus)\",tf_idf_vect.get_feature_names()[0:10])\n",
        "print('='*50)\n",
        "\n",
        "final_tf_idf = tf_idf_vect.transform(preprocessed_description)\n",
        "print(\"the type of count vectorizer \",type(final_tf_idf))\n",
        "print(\"the shape of out text TFIDF vectorizer \",final_tf_idf.get_shape())\n",
        "print(\"the number of unique words including both unigrams and bigrams \", final_tf_idf.get_shape()[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "some sample features(unique words in the corpus) ['ab', 'ab formerly', 'ab publ', 'ab sweden', 'ability', 'abitibi', 'abitibi greenstone', 'able', 'abroad', 'absorption']\n",
            "==================================================\n",
            "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
            "the shape of out text TFIDF vectorizer  (6045, 7682)\n",
            "the number of unique words including both unigrams and bigrams  7682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xf2YvQEmCMW"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_tf_idf, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doPCNC5Rkixw"
      },
      "source": [
        "**Training TF_IDF model on SVM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDfTaJ7Tl-Fw",
        "outputId": "558fb9c0-f7b3-4370-808a-9c8c12fabfec"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "idf_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of TF-IDF model in SVM algorithm : \",idf_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF-IDF model in SVM algorithm :  0.6752645502645502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngUzNjqzki9S"
      },
      "source": [
        "**Training TF_IDF model on Random Forest algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zOn6fiEl-jI",
        "outputId": "52f0cc1e-2765-4777-c434-98c00bcb83c0"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "idf_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of TF_IDF model in Random Forest algorithm : \",idf_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF_IDF model in Random Forest algorithm :  0.4103290836420923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeyIMRFqkjI-"
      },
      "source": [
        "**Training TF_IDF model on Naive Bayes algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3jSpG7Ml--T",
        "outputId": "04c013fd-ce3d-46e2-e744-b008c754f22b"
      },
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train_dense, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "idf_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of TF_IDF model in Naive Bayes algorithm : \",idf_nb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF_IDF model in Naive Bayes algorithm :  0.5337301587301587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpkrMlbCJ05D"
      },
      "source": [
        "## *Word2Vec*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmEqjyi5KNpj",
        "outputId": "660baffa-1da8-4631-b8cf-e8ca6d638ec5"
      },
      "source": [
        "#Training Word2Vec using our own Text corpus.\n",
        "\n",
        "list_of_sentance=[]\n",
        "for sentance in preprocessed_description:\n",
        "    list_of_sentance.append(sentance.split())\n",
        "\n",
        "w2v_model=Word2Vec(list_of_sentance,min_count=5,size=50, workers=4)\n",
        "print(\"Words similar to Company according to our corpus : \",w2v_model.wv.most_similar('company'))\n",
        "print('='*50)\n",
        "print(\"Words similar to Technologies according to our corpus : \",w2v_model.wv.most_similar('technologies'))\n",
        "\n",
        "w2v_words = list(w2v_model.wv.vocab)\n",
        "print('='*50)\n",
        "print(\"Number of words that occured minimum 5 times : \",len(w2v_words))\n",
        "print(\"Sample words \", w2v_words[0:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words similar to Company according to our corpus :  [('acquiring', 0.6578993797302246), ('principally', 0.6536482572555542), ('launching', 0.6526538729667664), ('licensing', 0.6384079456329346), ('owning', 0.6356709599494934), ('empowered', 0.6335441470146179), ('operating', 0.6292605400085449), ('diversified', 0.628777265548706), ('provision', 0.6278267502784729), ('cannabis', 0.6204374432563782)]\n",
            "==================================================\n",
            "Words similar to Technologies according to our corpus :  [('diagnostics', 0.9511491656303406), ('advanced', 0.891674816608429), ('science', 0.8850345015525818), ('pharmaceuticals', 0.8765751719474792), ('cgmp', 0.8624785542488098), ('biomedical', 0.8619247078895569), ('laboratory', 0.860388457775116), ('sciences', 0.8592849969863892), ('semiconductor', 0.8575431108474731), ('technology', 0.8572807908058167)]\n",
            "==================================================\n",
            "Number of words that occured minimum 5 times :  8311\n",
            "Sample words  ['partners', 'inc', 'provides', 'advertising', 'agency', 'services', 'specializing', 'direct', 'response', 'media', 'campaigns', 'also', 'owns', 'distribution', 'rights', 'number', 'products', 'acquired', 'business', 'consists', 'two', 'operating', 'sectors', 'year', 'ended', 'december', 'internally', 'developed', 'marketed', 'lines', 'branded', 'extreme', 'beam', 'light', 'company', 'obtained', 'exclusive', 'five', 'marketing', 'hook', 'anti', 'mist', 'organized', 'power', 'solutions', 'purpose', 'selling', 'installing', 'servicing', 'integrated']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0_YDd2nMNuJ"
      },
      "source": [
        "## *Converting text into vectors using Avg W2V and TFIDF-W2V*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-LHX9i8MZR7"
      },
      "source": [
        "### *Average Word2Vec*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IGQMB6TMBov",
        "outputId": "190c26ea-03fb-4b60-ce3d-2e6321d9b452"
      },
      "source": [
        "# average Word2Vec\n",
        "# compute average word2vec for each description.\n",
        "sent_vectors = []; # the avg-w2v for each sentence/description is stored in this list\n",
        "for sent in tqdm(list_of_sentance): # for each description/sentence\n",
        "    sent_vec = np.zeros(50) \n",
        "    cnt_words =0; # num of words with a valid vector in the sentence/description\n",
        "    for word in sent: # for each word in a description/sentence\n",
        "        if word in w2v_words:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words += 1\n",
        "    if cnt_words != 0:\n",
        "        sent_vec /= cnt_words\n",
        "    sent_vectors.append(sent_vec)\n",
        "\n",
        "print(len(sent_vectors))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6045/6045 [00:21<00:00, 275.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-AdSP5PnaDn"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(sent_vectors, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtoieyuunaVO"
      },
      "source": [
        "**Training Average Word2Vec model on SVM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-w8KveFnuUI",
        "outputId": "4bf81c95-c7e5-4951-820f-46ea9d585304"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "w2v_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of Word2Vec model in SVM algorithm : \",w2v_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Word2Vec model in SVM algorithm :  0.35714285714285715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mmzpBnOnagu"
      },
      "source": [
        "**Training Average Word2Vec model on Random Forest algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X0JAN4Dnuwh",
        "outputId": "9e1abde5-2e25-4163-a7d2-d3f697a4c12d"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "w2v_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of Word2Vec model in Random Forest algorithm : \",w2v_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Word2Vec model in Random Forest algorithm :  0.4502513833377095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXEQzv_5nasN"
      },
      "source": [
        "**Training Average Word2Vec model on Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cmdGSqwnvL9",
        "outputId": "f2f4eda4-c119-4242-d0e2-423b276a5df8"
      },
      "source": [
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "w2v_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of Word2Vec model in Naive Bayes algorithm : \",w2v_nb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Word2Vec model in Naive Bayes algorithm :  0.4279100529100529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw7CjRwaPR8d"
      },
      "source": [
        "### *TF-IDF Word2Vec*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP4xeP5FNeEt",
        "outputId": "e78d1bc8-e5db-4cf6-e3f5-58a3f861fd9a"
      },
      "source": [
        "model = TfidfVectorizer()\n",
        "model.fit(preprocessed_description)\n",
        "# we are converting a dictionary with word as a key, and the idf as a value\n",
        "dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))\n",
        "\n",
        "# TF-IDF weighted Word2Vec\n",
        "tfidf_feat = model.get_feature_names() # tfidf words/col-names\n",
        "\n",
        "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/description is stored in this list\n",
        "row=0;\n",
        "for sent in tqdm(list_of_sentance): # for each description/sentence \n",
        "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
        "    weight_sum =0; # num of words with a valid vector in the sentence/description\n",
        "    for word in sent: # for each word in a description/sentence\n",
        "        if word in w2v_words and word in tfidf_feat:\n",
        "            vec = w2v_model.wv[word]\n",
        "            # dictionary[word] = idf value of word in whole courpus\n",
        "            # sent.count(word) = tf valeus of word in this review\n",
        "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
        "            sent_vec += (vec * tf_idf)\n",
        "            weight_sum += tf_idf\n",
        "    if weight_sum != 0:\n",
        "        sent_vec /= weight_sum\n",
        "    tfidf_sent_vectors.append(sent_vec)\n",
        "    row += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6045/6045 [02:53<00:00, 34.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdZJ5EBJnxZX"
      },
      "source": [
        "#splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_sent_vectors, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEn9ShRonxov"
      },
      "source": [
        "**Training TF-IDF Word2Vec model on SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YMklHX5oIrY",
        "outputId": "d506c824-2fc2-41fe-b50e-15a3d7c0531e"
      },
      "source": [
        "classifier = SVC(kernel = 'sigmoid')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "tfw2v_svm = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of TF-IDF Word2Vec model in SVM algorithm : \",tfw2v_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF-IDF Word2Vec model in SVM algorithm :  0.30886243386243384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLHTQNjBnx0t"
      },
      "source": [
        "**Training TF-IDF Word2Vec model on Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maQzrgPjoJGF",
        "outputId": "2916d3fd-2e24-4e5b-b150-0ced5ad27e7c"
      },
      "source": [
        "estimators = list(range(1,20))\n",
        "cv_score = []\n",
        "\n",
        "for n in estimators:\n",
        "    random_forest = RandomForestClassifier(n_estimators = n, criterion = 'entropy')\n",
        "    scores = cross_val_score(random_forest, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    cv_score.append(scores.mean())\n",
        "\n",
        "tfw2v_rf = max(cv_score)\n",
        "\n",
        "print(\"Accuracy of TF_IDF Word2Vec model in Random Forest algorithm : \",tfw2v_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF_IDF Word2Vec model in Random Forest algorithm :  0.45687244118991355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji9XJRbknx-y"
      },
      "source": [
        "**Training TF-IDF Word2Vec model on Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF0uCxznoJkq",
        "outputId": "5e63cb7b-ceac-4e0a-e374-6e184cf06bb3"
      },
      "source": [
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "tfw2v_nb = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of TF_IDF Word2Vec model in Naive Bayes algorithm : \",tfw2v_nb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TF_IDF Word2Vec model in Naive Bayes algorithm :  0.38955026455026454\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}